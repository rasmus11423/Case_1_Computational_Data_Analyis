{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# k-NN, Decision Tree, Random Forest, SVM, Neural Network + Bagging, Boosting, CV, Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import Ridge, Lasso, LinearRegression, ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor, BaggingRegressor, AdaBoostRegressor, GradientBoostingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.svm import SVR\n",
    "from scipy.spatial import distance\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import warnings # to silence convergence warnings\n",
    "# Cross validation, bagging, boosting and oob for optimization\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn.ensemble import (RandomForestRegressor, AdaBoostRegressor, \n",
    "                             BaggingRegressor, GradientBoostingRegressor)\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor as WeightedKNNRegressor\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Functions from the exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def centerData(data):\n",
    "    \n",
    "    mu = np.mean(data,axis=0)\n",
    "    data = data - mu\n",
    "    \n",
    "    return data, mu\n",
    "\n",
    "def normalize(X):\n",
    "    '''\n",
    "    Function for normalizing the columns (variables) of a data matrix to unit length.\n",
    "    Returns the normalized data and the L2 norm of the variables \n",
    "    \n",
    "    Input  (X) --------> The data matrix to be normalized \n",
    "    Output (X_pre)-----> The normalized data matrix \n",
    "    Output (d) --------> Array with the L2 norms of the variables \n",
    "    '''\n",
    "    d = np.linalg.norm(X,axis=0,ord=2)  # d is the euclidian lenghts of the variables \n",
    "    d[d==0]=1                           # Avoid dividing by zero if column L2 norm is zero \n",
    "    X_pre = X / d                       # Normalize the data with the euclidian lengths\n",
    "    return X_pre,d                      # Return normalized data and the euclidian lengths\n",
    "\n",
    "def weighted_knn(K, X, n):\n",
    "    yhat = np.zeros(n)\n",
    "    distances = np.zeros(n)\n",
    "    # For each obs, compare distance to all other points in X\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            distances[j] = distance.euclidean(X[i,:], X[j, :])\n",
    "\n",
    "        # Sort all the distances\n",
    "        idx = np.argsort(distances)[1:(K + 1)] # Skip first, as distance to \"itself\" does not make sense\n",
    "        Wt = sum(distances[idx]) # Weight of k nearest neighbors\n",
    "        W = distances[idx] / Wt # Weighing average\n",
    "\n",
    "\n",
    "        yhat[i] = np.matmul(W.T, y[idx]) # Final value is weighted combination of neighbours\n",
    "    \n",
    "    return yhat\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "\n",
    "class WeightedKNNRegressor(BaseEstimator, RegressorMixin):\n",
    "\tdef __init__(self, K):\n",
    "\t\tself.K = K\n",
    "\n",
    "\tdef fit(self, X, y):\n",
    "\t\tself.X = X\n",
    "\t\tself.y = y\n",
    "\n",
    "\tdef predict(self, X):\n",
    "\t\tn = X.shape[0]\n",
    "\t\tyhat = np.zeros(n)\n",
    "\t\tfor i in range(n):\n",
    "\t\t\tdistances = np.array([distance.euclidean(X[i], x) for x in self.X])\n",
    "\t\t\tidx = np.argsort(distances)[:self.K]\n",
    "\t\t\tWt = sum(distances[idx])\n",
    "\t\t\tW = distances[idx] / Wt\n",
    "\t\t\tyhat[i] = np.dot(W, self.y[idx])\n",
    "\t\treturn yhat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load and format data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./Data/case1Data.csv')\n",
    "y = np.array(data['y'])\n",
    "X = np.array(data.drop('y', axis=1).fillna(data.mean()))\n",
    "data = pd.read_csv('./Data/case1Data_Xnew.csv')\n",
    "X_new = np.array(data.fillna(data.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_transform_data(X):\n",
    "    # Round the last 5 columns to integers\n",
    "    X[:, -5:] = np.round(X[:, -5:])\n",
    "\n",
    "    # Convert to integers, then to strings to force categorical treatment\n",
    "    cat_data = X[:, -5:].astype(int).astype(str)\n",
    "    cat_df = pd.DataFrame(cat_data)\n",
    "    cat = pd.get_dummies(cat_df).values\n",
    "\n",
    "    # Separate numerical columns\n",
    "    num = X[:, :-5]\n",
    "    # Standardize numerical columns\n",
    "    num, mu = centerData(num)\n",
    "    num, d = normalize(num)   \n",
    "\n",
    "    # Concatenate numerical and one-hot encoded categorical columns\n",
    "    X = np.concatenate((num, cat), axis=1)\n",
    "\n",
    "    return X, mu, d\n",
    "\n",
    "def transform_data(X, mu, d):\n",
    "    # Round the last 5 columns to integers\n",
    "    X[:, -5:] = np.round(X[:, -5:])\n",
    "\n",
    "    # Convert to integers, then to strings to force categorical treatment\n",
    "    cat_data = X[:, -5:].astype(int).astype(str)\n",
    "    cat_df = pd.DataFrame(cat_data)\n",
    "    cat = pd.get_dummies(cat_df).values\n",
    "\n",
    "    # Separate numerical columns\n",
    "    num = X[:, :-5]\n",
    "    # Standardize numerical columns using the mean and std from the training set\n",
    "    num = (num - mu) / d\n",
    "\n",
    "    # Concatenate numerical and one-hot encoded categorical columns\n",
    "    X = np.concatenate((num, cat), axis=1)\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=0.9)\n",
    "pca_plot = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X)\n",
    "X_pca_plot = pca_plot.fit_transform(X)\n",
    "\n",
    "X_pca_train, X_pca_test, y_pca_train, y_pca_test = train_test_split(X_pca, y, test_size=0.2, random_state=1312)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot pca\n",
    "\n",
    "plt.scatter(X_pca_plot[:,0], X_pca_plot[:,1], c=y, cmap='viridis')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model defitinions\n",
    "rf = RandomForestRegressor(random_state=1312)\n",
    "dt = DecisionTreeRegressor(random_state=1312)\n",
    "svr = SVR()\n",
    "ada = AdaBoostRegressor(random_state=1312)\n",
    "bag = BaggingRegressor(random_state=1312)\n",
    "dt = DecisionTreeRegressor(random_state=1312)\n",
    "knn = WeightedKNNRegressor(5)\n",
    "ols = LinearRegression() \n",
    "rr = Ridge() \n",
    "lasso = Lasso()\n",
    "elnet = ElasticNet()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== PERMUTATION 1/5 ===\n",
      "\n",
      "--- VANILLA MODELS ---\n",
      "\n",
      "Evaluating RandomForest...\n",
      "RandomForest - Best params: {'n_estimators': 50, 'max_depth': None}\n",
      "RandomForest - Best CV RMSE: 50.2752\n",
      "\n",
      "Evaluating DecisionTree...\n",
      "DecisionTree - Best params: {'max_depth': None}\n",
      "DecisionTree - Best CV RMSE: 64.5854\n",
      "\n",
      "Evaluating SVR...\n",
      "SVR - Best params: {'C': 10, 'gamma': 'auto'}\n",
      "SVR - Best CV RMSE: 72.4945\n",
      "\n",
      "Evaluating KNN...\n",
      "KNN - Best params: {'n_neighbors': 20}\n",
      "KNN - Best CV RMSE: 73.4181\n",
      "\n",
      "Evaluating AdaBoost...\n",
      "AdaBoost - Best params: {'n_estimators': 500}\n",
      "AdaBoost - Best CV RMSE: 51.1349\n",
      "\n",
      "Evaluating Bagging...\n",
      "Bagging - Best params: {'n_estimators': 200}\n",
      "Bagging - Best CV RMSE: 50.1856\n",
      "\n",
      "Evaluating OLS...\n",
      "OLS - No params to tune - CV RMSE: 56.2573\n",
      "\n",
      "Evaluating Ridge...\n",
      "Ridge - Best params: {'alpha': np.float64(0.042169650342858224)}\n",
      "Ridge - Best CV RMSE: 53.4724\n",
      "\n",
      "Evaluating Lasso...\n",
      "Lasso - Best params: {'alpha': np.float64(0.27384196342643613)}\n",
      "Lasso - Best CV RMSE: 40.4031\n",
      "\n",
      "Evaluating ElasticNet...\n",
      "ElasticNet - Best params: {'alpha': np.float64(0.006493816315762113), 'l1_ratio': 0.9}\n",
      "ElasticNet - Best CV RMSE: 52.7067\n",
      "\n",
      "=== PERMUTATION 2/5 ===\n",
      "\n",
      "--- VANILLA MODELS ---\n",
      "\n",
      "Evaluating RandomForest...\n",
      "RandomForest - Best params: {'n_estimators': 200, 'max_depth': 10}\n",
      "RandomForest - Best CV RMSE: 49.9222\n",
      "\n",
      "Evaluating DecisionTree...\n",
      "DecisionTree - Best params: {'max_depth': 10}\n",
      "DecisionTree - Best CV RMSE: 61.8741\n",
      "\n",
      "Evaluating SVR...\n",
      "SVR - Best params: {'C': 10, 'gamma': 'scale'}\n",
      "SVR - Best CV RMSE: 72.3802\n",
      "\n",
      "Evaluating KNN...\n",
      "KNN - Best params: {'n_neighbors': 20}\n",
      "KNN - Best CV RMSE: 70.0435\n",
      "\n",
      "Evaluating AdaBoost...\n",
      "AdaBoost - Best params: {'n_estimators': 100}\n",
      "AdaBoost - Best CV RMSE: 50.6299\n",
      "\n",
      "Evaluating Bagging...\n",
      "Bagging - Best params: {'n_estimators': 200}\n",
      "Bagging - Best CV RMSE: 50.1032\n",
      "\n",
      "Evaluating OLS...\n",
      "OLS - No params to tune - CV RMSE: 50.3440\n",
      "\n",
      "Evaluating Ridge...\n",
      "Ridge - Best params: {'alpha': np.float64(0.042169650342858224)}\n",
      "Ridge - Best CV RMSE: 46.6679\n",
      "\n",
      "Evaluating Lasso...\n",
      "Lasso - Best params: {'alpha': np.float64(0.27384196342643613)}\n",
      "Lasso - Best CV RMSE: 42.8328\n",
      "\n",
      "Evaluating ElasticNet...\n",
      "ElasticNet - Best params: {'alpha': np.float64(0.006493816315762113), 'l1_ratio': 0.9}\n",
      "ElasticNet - Best CV RMSE: 45.6743\n",
      "\n",
      "=== PERMUTATION 3/5 ===\n",
      "\n",
      "--- VANILLA MODELS ---\n",
      "\n",
      "Evaluating RandomForest...\n",
      "RandomForest - Best params: {'n_estimators': 100, 'max_depth': None}\n",
      "RandomForest - Best CV RMSE: 51.2693\n",
      "\n",
      "Evaluating DecisionTree...\n",
      "DecisionTree - Best params: {'max_depth': 10}\n",
      "DecisionTree - Best CV RMSE: 73.6490\n",
      "\n",
      "Evaluating SVR...\n",
      "SVR - Best params: {'C': 10, 'gamma': 'auto'}\n",
      "SVR - Best CV RMSE: 72.2498\n",
      "\n",
      "Evaluating KNN...\n",
      "KNN - Best params: {'n_neighbors': 20}\n",
      "KNN - Best CV RMSE: 74.3003\n",
      "\n",
      "Evaluating AdaBoost...\n",
      "AdaBoost - Best params: {'n_estimators': 50}\n",
      "AdaBoost - Best CV RMSE: 51.6775\n",
      "\n",
      "Evaluating Bagging...\n",
      "Bagging - Best params: {'n_estimators': 200}\n",
      "Bagging - Best CV RMSE: 51.5436\n",
      "\n",
      "Evaluating OLS...\n",
      "OLS - No params to tune - CV RMSE: 53.8476\n",
      "\n",
      "Evaluating Ridge...\n",
      "Ridge - Best params: {'alpha': np.float64(0.042169650342858224)}\n",
      "Ridge - Best CV RMSE: 52.6594\n",
      "\n",
      "Evaluating Lasso...\n",
      "Lasso - Best params: {'alpha': np.float64(0.27384196342643613)}\n",
      "Lasso - Best CV RMSE: 39.9706\n",
      "\n",
      "Evaluating ElasticNet...\n",
      "ElasticNet - Best params: {'alpha': np.float64(0.006493816315762113), 'l1_ratio': 0.9}\n",
      "ElasticNet - Best CV RMSE: 52.0017\n",
      "\n",
      "=== PERMUTATION 4/5 ===\n",
      "\n",
      "--- VANILLA MODELS ---\n",
      "\n",
      "Evaluating RandomForest...\n",
      "RandomForest - Best params: {'n_estimators': 200, 'max_depth': 10}\n",
      "RandomForest - Best CV RMSE: 47.2603\n",
      "\n",
      "Evaluating DecisionTree...\n",
      "DecisionTree - Best params: {'max_depth': 10}\n",
      "DecisionTree - Best CV RMSE: 63.5368\n",
      "\n",
      "Evaluating SVR...\n",
      "SVR - Best params: {'C': 10, 'gamma': 'scale'}\n",
      "SVR - Best CV RMSE: 70.4867\n",
      "\n",
      "Evaluating KNN...\n",
      "KNN - Best params: {'n_neighbors': 20}\n",
      "KNN - Best CV RMSE: 69.5228\n",
      "\n",
      "Evaluating AdaBoost...\n",
      "AdaBoost - Best params: {'n_estimators': 500}\n",
      "AdaBoost - Best CV RMSE: 47.6766\n",
      "\n",
      "Evaluating Bagging...\n",
      "Bagging - Best params: {'n_estimators': 500}\n",
      "Bagging - Best CV RMSE: 46.9075\n",
      "\n",
      "Evaluating OLS...\n",
      "OLS - No params to tune - CV RMSE: 48.0456\n",
      "\n",
      "Evaluating Ridge...\n",
      "Ridge - Best params: {'alpha': np.float64(0.042169650342858224)}\n",
      "Ridge - Best CV RMSE: 45.9934\n",
      "\n",
      "Evaluating Lasso...\n",
      "Lasso - Best params: {'alpha': np.float64(0.27384196342643613)}\n",
      "Lasso - Best CV RMSE: 38.2945\n",
      "\n",
      "Evaluating ElasticNet...\n",
      "ElasticNet - Best params: {'alpha': np.float64(0.006493816315762113), 'l1_ratio': 0.9}\n",
      "ElasticNet - Best CV RMSE: 45.4030\n",
      "\n",
      "=== PERMUTATION 5/5 ===\n",
      "\n",
      "--- VANILLA MODELS ---\n",
      "\n",
      "Evaluating RandomForest...\n",
      "RandomForest - Best params: {'n_estimators': 100, 'max_depth': 10}\n",
      "RandomForest - Best CV RMSE: 48.3416\n",
      "\n",
      "Evaluating DecisionTree...\n",
      "DecisionTree - Best params: {'max_depth': 10}\n",
      "DecisionTree - Best CV RMSE: 68.5490\n",
      "\n",
      "Evaluating SVR...\n",
      "SVR - Best params: {'C': 1, 'gamma': 'auto'}\n",
      "SVR - Best CV RMSE: 73.5299\n",
      "\n",
      "Evaluating KNN...\n",
      "KNN - Best params: {'n_neighbors': 20}\n",
      "KNN - Best CV RMSE: 75.6032\n",
      "\n",
      "Evaluating AdaBoost...\n",
      "AdaBoost - Best params: {'n_estimators': 50}\n",
      "AdaBoost - Best CV RMSE: 49.6183\n",
      "\n",
      "Evaluating Bagging...\n",
      "Bagging - Best params: {'n_estimators': 100}\n",
      "Bagging - Best CV RMSE: 48.2198\n",
      "\n",
      "Evaluating OLS...\n",
      "OLS - No params to tune - CV RMSE: 46.7354\n",
      "\n",
      "Evaluating Ridge...\n",
      "Ridge - Best params: {'alpha': np.float64(0.042169650342858224)}\n",
      "Ridge - Best CV RMSE: 43.4997\n",
      "\n",
      "Evaluating Lasso...\n",
      "Lasso - Best params: {'alpha': np.float64(0.27384196342643613)}\n",
      "Lasso - Best CV RMSE: 36.6758\n",
      "\n",
      "Evaluating ElasticNet...\n",
      "ElasticNet - Best params: {'alpha': np.float64(0.006493816315762113), 'l1_ratio': 0.9}\n",
      "ElasticNet - Best CV RMSE: 43.0405\n",
      "\n",
      "=== BOOSTED MODELS ===\n",
      "\n",
      "Evaluating AdaBoost_DecisionTree...\n",
      "AdaBoost_DecisionTree - Best CV RMSE: 49.2442\n",
      "\n",
      "Evaluating GradientBoosting...\n",
      "GradientBoosting - Best CV RMSE: 44.5181\n",
      "\n",
      "Evaluating AdaBoost_OLS...\n",
      "AdaBoost_OLS - Best CV RMSE: 54.3894\n",
      "\n",
      "Evaluating AdaBoost_Ridge...\n",
      "AdaBoost_Ridge - Best CV RMSE: 54.5800\n",
      "\n",
      "Evaluating AdaBoost_Lasso...\n",
      "AdaBoost_Lasso - Best CV RMSE: 39.5812\n",
      "\n",
      "=== BAGGED MODELS ===\n",
      "\n",
      "Evaluating Bagging_RandomForest...\n",
      "Bagging_RandomForest - Best CV RMSE: 51.4874\n",
      "\n",
      "Evaluating Bagging_DecisionTree...\n",
      "Bagging_DecisionTree - Best CV RMSE: 50.3544\n",
      "\n",
      "Evaluating Bagging_KNN...\n",
      "Bagging_KNN - Best CV RMSE: 69.4821\n",
      "\n",
      "Evaluating Bagging_OLS...\n",
      "Bagging_OLS - Best CV RMSE: 53.1087\n",
      "\n",
      "Evaluating Bagging_Ridge...\n",
      "Bagging_Ridge - Best CV RMSE: 53.9846\n",
      "\n",
      "Evaluating Bagging_Lasso...\n",
      "Bagging_Lasso - Best CV RMSE: 38.9768\n",
      "\n",
      "=== FINAL MODEL EVALUATION ON TEST SET ===\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 100 features, but RandomForestRegressor is expecting 116 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[68], line 420\u001b[0m\n\u001b[0;32m    417\u001b[0m X_test_scaled \u001b[38;5;241m=\u001b[39m X_test_scaled\u001b[38;5;241m.\u001b[39mreindex(columns\u001b[38;5;241m=\u001b[39mX_test_processed\u001b[38;5;241m.\u001b[39mcolumns, fill_value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    419\u001b[0m \u001b[38;5;66;03m# Make predictions and calculate RMSE\u001b[39;00m\n\u001b[1;32m--> 420\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test_scaled\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    421\u001b[0m test_rmse \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msqrt(mean_squared_error(y_final_test, y_pred))\n\u001b[0;32m    422\u001b[0m test_results[model_name] \u001b[38;5;241m=\u001b[39m test_rmse\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_forest.py:1063\u001b[0m, in \u001b[0;36mForestRegressor.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m   1061\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m   1062\u001b[0m \u001b[38;5;66;03m# Check data\u001b[39;00m\n\u001b[1;32m-> 1063\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_X_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1065\u001b[0m \u001b[38;5;66;03m# Assign chunk of trees to jobs\u001b[39;00m\n\u001b[0;32m   1066\u001b[0m n_jobs, _, _ \u001b[38;5;241m=\u001b[39m _partition_estimators(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_estimators, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_forest.py:641\u001b[0m, in \u001b[0;36mBaseForest._validate_X_predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    638\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    639\u001b[0m     force_all_finite \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 641\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    642\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    643\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDTYPE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    644\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    645\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    646\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    647\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    648\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m issparse(X) \u001b[38;5;129;01mand\u001b[39;00m (X\u001b[38;5;241m.\u001b[39mindices\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mintc \u001b[38;5;129;01mor\u001b[39;00m X\u001b[38;5;241m.\u001b[39mindptr\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mintc):\n\u001b[0;32m    649\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo support for np.int64 index based sparse matrices\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py:654\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    651\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    653\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m--> 654\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_n_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    656\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py:443\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    440\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    442\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_features \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_:\n\u001b[1;32m--> 443\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    444\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features, but \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    445\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis expecting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features as input.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    446\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: X has 100 features, but RandomForestRegressor is expecting 116 features as input."
     ]
    }
   ],
   "source": [
    "# Custom cross-validation, bagging, boosting and oob for optimization\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.ensemble import (RandomForestRegressor, AdaBoostRegressor, \n",
    "                             BaggingRegressor, GradientBoostingRegressor)\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor as WeightedKNNRegressor\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "from itertools import product\n",
    "import copy\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "X_dev, X_final_test, y_dev, y_final_test = train_test_split(X, y, test_size=0.2, random_state=1312)\n",
    "\n",
    "columns = []\n",
    "\n",
    "# Define the models and their parameter grids\n",
    "models = {\n",
    "    'RandomForest': (RandomForestRegressor(random_state=1312), \n",
    "                   {'n_estimators': [50, 100, 200], 'max_depth': [None, 10, 20, 30]}),\n",
    "    'DecisionTree': (DecisionTreeRegressor(random_state=1312), \n",
    "                   {'max_depth': [None, 10, 20, 30]}),\n",
    "    'SVR': (SVR(), \n",
    "          {'C': [0.1, 1, 10], 'gamma': ['scale', 'auto']}), \n",
    "    'KNN': (WeightedKNNRegressor(), \n",
    "          {'n_neighbors': [5, 10, 20]}), \n",
    "    'AdaBoost': (AdaBoostRegressor(random_state=1312), \n",
    "               {'n_estimators': [10, 50, 100, 200, 500]}), \n",
    "    'Bagging': (BaggingRegressor(random_state=1312), \n",
    "              {'n_estimators': [10, 50, 100, 200, 500]}),\n",
    "    'OLS': (LinearRegression(), {}),\n",
    "    'Ridge': (Ridge(random_state=1312), \n",
    "            {'alpha': np.logspace(-3, 0.25, num=5)}),\n",
    "    'Lasso': (Lasso(random_state=1312), \n",
    "            {'alpha': np.logspace(-3, 0.25, num=5)}),\n",
    "    'ElasticNet': (ElasticNet(random_state=1312), \n",
    "                 {'alpha': np.logspace(-3, 0.25, num=5), \n",
    "                  'l1_ratio': [0.1, 0.5, 0.7, 0.9]})\n",
    "}\n",
    "\n",
    "# Number of permutations to run\n",
    "n_permutations = 5\n",
    "# Number of CV folds\n",
    "n_splits = 5\n",
    "\n",
    "# Results storage\n",
    "all_results = {\n",
    "    'vanilla': {},\n",
    "    'bagged': {},\n",
    "    'boosted': {}\n",
    "}\n",
    "\n",
    "# Best model tracking\n",
    "best_estimators = {}\n",
    "best_params = {}\n",
    "best_cv_scores = {}\n",
    "\n",
    "# OUTER LOOP - handles permutation and data preprocessing\n",
    "for perm_idx in range(n_permutations):\n",
    "    print(f\"\\n=== PERMUTATION {perm_idx+1}/{n_permutations} ===\")\n",
    "    \n",
    "    # 1. Permute the data\n",
    "    random_state = 1312 + perm_idx\n",
    "    indices = np.random.RandomState(random_state).permutation(len(X_dev))\n",
    "    X_permuted, y_permuted = X_dev[indices], y_dev[indices]\n",
    "    \n",
    "    # 2. Set up cross-validation\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "    \n",
    "    # VANILLA MODELS\n",
    "    print(\"\\n--- VANILLA MODELS ---\")\n",
    "    for model_name, (base_model, param_grid) in models.items():\n",
    "        print(f\"\\nEvaluating {model_name}...\")\n",
    "        \n",
    "        # Initialize tracking for this model\n",
    "        if model_name not in best_cv_scores:\n",
    "            best_cv_scores[model_name] = float('inf')\n",
    "            best_params[model_name] = {}\n",
    "            all_results['vanilla'][model_name] = []\n",
    "        \n",
    "        # If no parameters to tune, just do simple CV\n",
    "        if not param_grid:\n",
    "            fold_scores = []\n",
    "            for fold_idx, (train_idx, val_idx) in enumerate(kf.split(X_permuted)):\n",
    "                # Get fold data\n",
    "                X_fold_train, X_fold_val = X_permuted[train_idx], X_permuted[val_idx]\n",
    "                y_fold_train, y_fold_val = y_permuted[train_idx], y_permuted[val_idx]\n",
    "                \n",
    "                # 3. Fill NA values in this fold\n",
    "                # Convert to DataFrame for easier handling of NaN values\n",
    "                X_fold_train_df = pd.DataFrame(X_fold_train)\n",
    "                X_fold_val_df = pd.DataFrame(X_fold_val)\n",
    "                \n",
    "                # Fill NaN values with mean of training data\n",
    "                for col in X_fold_train_df.columns:\n",
    "                    fill_value = X_fold_train_df[col].mean()\n",
    "                    X_fold_train_df[col] = X_fold_train_df[col].fillna(fill_value)\n",
    "                    X_fold_val_df[col] = X_fold_val_df[col].fillna(fill_value)\n",
    "                \n",
    "                # 4. Standardize the data using training fold stats\n",
    "                X_fold_train_scaled, mu, d = fit_transform_data(X_fold_train_df.values)\n",
    "                X_fold_val_scaled = transform_data(X_fold_val_df.values, mu, d)\n",
    "                \n",
    "                # Ensure both train and val sets have the same columns after one-hot encoding\n",
    "                X_fold_train_scaled = pd.DataFrame(X_fold_train_scaled)\n",
    "                X_fold_val_scaled = pd.DataFrame(X_fold_val_scaled)\n",
    "                X_fold_val_scaled = X_fold_val_scaled.reindex(columns=X_fold_train_scaled.columns, fill_value=0)\n",
    "\n",
    "                # Train and evaluate model\n",
    "                model = copy.deepcopy(base_model)\n",
    "                model.fit(X_fold_train_scaled, y_fold_train)\n",
    "                y_pred = model.predict(X_fold_val_scaled)\n",
    "                mse = mean_squared_error(y_fold_val, y_pred)\n",
    "                rmse = np.sqrt(mse)\n",
    "                fold_scores.append(rmse)\n",
    "                \n",
    "            # Average the fold scores\n",
    "            avg_rmse = np.mean(fold_scores)\n",
    "            all_results['vanilla'][model_name].append(avg_rmse)\n",
    "            \n",
    "            print(f\"{model_name} - No params to tune - CV RMSE: {avg_rmse:.4f}\")\n",
    "            \n",
    "            # Check if this is the best score so far\n",
    "            if avg_rmse < best_cv_scores[model_name]:\n",
    "                best_cv_scores[model_name] = avg_rmse\n",
    "                # Train on all dev data for final evaluation\n",
    "                X_dev_df = pd.DataFrame(X_dev)\n",
    "                for col in X_dev_df.columns:\n",
    "                    X_dev_df[col] = X_dev_df[col].fillna(X_dev_df[col].mean())\n",
    "                \n",
    "                X_dev_scaled, mu, d = fit_transform_data(X_dev_df.values)\n",
    "                \n",
    "                scaler = [mu, d]\n",
    "\n",
    "                best_model = copy.deepcopy(base_model)\n",
    "                best_model.fit(X_dev_scaled, y_dev)\n",
    "                best_estimators[model_name] = (best_model, scaler)\n",
    "        \n",
    "        else:\n",
    "            # INNER LOOP - hyperparameter tuning\n",
    "            # Generate all parameter combinations\n",
    "            param_keys = list(param_grid.keys())\n",
    "            param_values = list(param_grid.values())\n",
    "            param_combinations = list(product(*param_values))\n",
    "            \n",
    "            best_avg_rmse = float('inf')\n",
    "            best_param_combo = None\n",
    "            \n",
    "            for param_idx, param_combo in enumerate(param_combinations):\n",
    "                param_dict = {key: value for key, value in zip(param_keys, param_combo)}\n",
    "                \n",
    "                fold_scores = []\n",
    "                for fold_idx, (train_idx, val_idx) in enumerate(kf.split(X_permuted)):\n",
    "                    # Get fold data\n",
    "                    X_fold_train, X_fold_val = X_permuted[train_idx], X_permuted[val_idx]\n",
    "                    y_fold_train, y_fold_val = y_permuted[train_idx], y_permuted[val_idx]\n",
    "                    \n",
    "                    # 3. Fill NA values\n",
    "                    X_fold_train_df = pd.DataFrame(X_fold_train)\n",
    "                    X_fold_val_df = pd.DataFrame(X_fold_val)\n",
    "                    \n",
    "                    for col in X_fold_train_df.columns:\n",
    "                        fill_value = X_fold_train_df[col].mean()\n",
    "                        X_fold_train_df[col] = X_fold_train_df[col].fillna(fill_value)\n",
    "                        X_fold_val_df[col] = X_fold_val_df[col].fillna(fill_value)\n",
    "                    \n",
    "                    # 4. Standardize\n",
    "                    X_fold_train_scaled, mu, d = fit_transform_data(X_fold_train_df.values)\n",
    "                    X_fold_val_scaled = transform_data(X_fold_val_df.values, mu, d)\n",
    "\n",
    "                    # Ensure both train and val sets have the same columns after one-hot encoding\n",
    "                    X_fold_train_scaled = pd.DataFrame(X_fold_train_scaled)\n",
    "                    X_fold_val_scaled = pd.DataFrame(X_fold_val_scaled)\n",
    "                    X_fold_val_scaled = X_fold_val_scaled.reindex(columns=X_fold_train_scaled.columns, fill_value=0)\n",
    "\n",
    "                    # Create model with current parameters\n",
    "                    model = copy.deepcopy(base_model)\n",
    "                    model.set_params(**param_dict)\n",
    "                    \n",
    "                    # Train and evaluate\n",
    "                    model.fit(X_fold_train_scaled, y_fold_train)\n",
    "                    y_pred = model.predict(X_fold_val_scaled)\n",
    "                    mse = mean_squared_error(y_fold_val, y_pred)\n",
    "                    rmse = np.sqrt(mse)\n",
    "                    fold_scores.append(rmse)\n",
    "                \n",
    "                # Average the fold scores for this parameter combination\n",
    "                avg_rmse = np.mean(fold_scores)\n",
    "                \n",
    "                # Check if this is the best parameter combination\n",
    "                if avg_rmse < best_avg_rmse:\n",
    "                    best_avg_rmse = avg_rmse\n",
    "                    best_param_combo = param_dict\n",
    "            \n",
    "            # Record results for this permutation\n",
    "            all_results['vanilla'][model_name].append(best_avg_rmse)\n",
    "            \n",
    "            print(f\"{model_name} - Best params: {best_param_combo}\")\n",
    "            print(f\"{model_name} - Best CV RMSE: {best_avg_rmse:.4f}\")\n",
    "            \n",
    "            # Check if this is the best score across all permutations\n",
    "            if best_avg_rmse < best_cv_scores[model_name]:\n",
    "                best_cv_scores[model_name] = best_avg_rmse\n",
    "                best_params[model_name] = best_param_combo\n",
    "                \n",
    "                # Train on all dev data with best parameters\n",
    "                X_dev_df = pd.DataFrame(X_dev)\n",
    "                for col in X_dev_df.columns:\n",
    "                    X_dev_df[col] = X_dev_df[col].fillna(X_dev_df[col].mean())\n",
    "                \n",
    "                X_dev_scaled, mu, d = fit_transform_data(X_dev_df.values)\n",
    "                scaler = [mu, d]\n",
    "                \n",
    "                best_model = copy.deepcopy(base_model)\n",
    "                best_model.set_params(**best_param_combo)\n",
    "                best_model.fit(X_dev_scaled, y_dev)\n",
    "                best_estimators[model_name] = (best_model, scaler)\n",
    "\n",
    "# After all permutations, evaluate BOOSTED models\n",
    "print(\"\\n=== BOOSTED MODELS ===\")\n",
    "boosted_models = {\n",
    "    'AdaBoost_DecisionTree': (AdaBoostRegressor(\n",
    "        estimator=best_estimators['DecisionTree'][0], n_estimators=100, random_state=1312), {}),\n",
    "    'GradientBoosting': (GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, random_state=1312), {}),\n",
    "    'AdaBoost_OLS': (AdaBoostRegressor(\n",
    "        estimator=best_estimators['OLS'][0], n_estimators=100, random_state=1312), {}),\n",
    "    'AdaBoost_Ridge': (AdaBoostRegressor(\n",
    "        estimator=best_estimators['Ridge'][0], n_estimators=100, random_state=1312), {}),\n",
    "    'AdaBoost_Lasso': (AdaBoostRegressor(\n",
    "        estimator=best_estimators['Lasso'][0], n_estimators=100, random_state=1312), {})\n",
    "}\n",
    "\n",
    "# Run similar CV process for boosted models\n",
    "for model_name, (base_model, _) in boosted_models.items():\n",
    "    print(f\"\\nEvaluating {model_name}...\")\n",
    "    \n",
    "    # Initialize tracking\n",
    "    best_cv_scores[model_name] = float('inf')\n",
    "    all_results['boosted'][model_name] = []\n",
    "    \n",
    "    # Run through permutations\n",
    "    for perm_idx in range(n_permutations):\n",
    "        random_state = 1312 + perm_idx\n",
    "        indices = np.random.RandomState(random_state).permutation(len(X_dev))\n",
    "        X_permuted, y_permuted = X_dev[indices], y_dev[indices]\n",
    "        \n",
    "        kf = KFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "        fold_scores = []\n",
    "        \n",
    "        for fold_idx, (train_idx, val_idx) in enumerate(kf.split(X_permuted)):\n",
    "            # Get fold data\n",
    "            X_fold_train, X_fold_val = X_permuted[train_idx], X_permuted[val_idx]\n",
    "            y_fold_train, y_fold_val = y_permuted[train_idx], y_permuted[val_idx]\n",
    "            \n",
    "            # Preprocess\n",
    "            X_fold_train_df = pd.DataFrame(X_fold_train)\n",
    "            X_fold_val_df = pd.DataFrame(X_fold_val)\n",
    "            \n",
    "            for col in X_fold_train_df.columns:\n",
    "                fill_value = X_fold_train_df[col].mean()\n",
    "                X_fold_train_df[col] = X_fold_train_df[col].fillna(fill_value)\n",
    "                X_fold_val_df[col] = X_fold_val_df[col].fillna(fill_value)\n",
    "            \n",
    "            X_fold_train_scaled, mu, d = fit_transform_data(X_fold_train_df.values)\n",
    "            X_fold_val_scaled = transform_data(X_fold_val_df.values, mu, d)\n",
    "\n",
    "            # Make sure both train and val sets have the same columns after one-hot encoding\n",
    "            X_fold_train_scaled = pd.DataFrame(X_fold_train_scaled)\n",
    "            X_fold_val_scaled = pd.DataFrame(X_fold_val_scaled)\n",
    "            X_fold_val_scaled = X_fold_val_scaled.reindex(columns=X_fold_train_scaled.columns, fill_value=0)\n",
    "            \n",
    "            # Train and evaluate\n",
    "            model = copy.deepcopy(base_model)\n",
    "            model.fit(X_fold_train_scaled, y_fold_train)\n",
    "            y_pred = model.predict(X_fold_val_scaled)\n",
    "            mse = mean_squared_error(y_fold_val, y_pred)\n",
    "            rmse = np.sqrt(mse)\n",
    "            fold_scores.append(rmse)\n",
    "        \n",
    "        # Average the fold scores\n",
    "        avg_rmse = np.mean(fold_scores)\n",
    "        all_results['boosted'][model_name].append(avg_rmse)\n",
    "        \n",
    "        # Check if this is the best score\n",
    "        if avg_rmse < best_cv_scores[model_name]:\n",
    "            best_cv_scores[model_name] = avg_rmse\n",
    "            \n",
    "            # Train on all dev data\n",
    "            X_dev_df = pd.DataFrame(X_dev)\n",
    "            for col in X_dev_df.columns:\n",
    "                X_dev_df[col] = X_dev_df[col].fillna(X_dev_df[col].mean())\n",
    "            \n",
    "            X_dev_scaled, mu, d = fit_transform_data(X_dev_df.values)\n",
    "            scaler = [mu, d]\n",
    "\n",
    "            best_model = copy.deepcopy(base_model)\n",
    "            best_model.fit(X_dev_scaled, y_dev)\n",
    "            best_estimators[model_name] = (best_model, scaler)\n",
    "    \n",
    "    print(f\"{model_name} - Best CV RMSE: {best_cv_scores[model_name]:.4f}\")\n",
    "\n",
    "# BAGGED models\n",
    "print(\"\\n=== BAGGED MODELS ===\")\n",
    "bagging_models = {\n",
    "    'Bagging_RandomForest': (BaggingRegressor(\n",
    "        estimator=best_estimators['RandomForest'][0], n_estimators=10, random_state=1312), {}),\n",
    "    'Bagging_DecisionTree': (BaggingRegressor(\n",
    "        estimator=best_estimators['DecisionTree'][0], n_estimators=10, random_state=1312), {}),\n",
    "    'Bagging_KNN': (BaggingRegressor(\n",
    "        estimator=best_estimators['KNN'][0], n_estimators=10, random_state=1312), {}),\n",
    "    'Bagging_OLS': (BaggingRegressor(\n",
    "        estimator=best_estimators['OLS'][0], n_estimators=10, random_state=1312), {}),\n",
    "    'Bagging_Ridge': (BaggingRegressor(\n",
    "        estimator=best_estimators['Ridge'][0], n_estimators=10, random_state=1312), {}),\n",
    "    'Bagging_Lasso': (BaggingRegressor(\n",
    "        estimator=best_estimators['Lasso'][0], n_estimators=10, random_state=1312), {})\n",
    "}\n",
    "\n",
    "# Run similar CV process for bagged models\n",
    "for model_name, (base_model, _) in bagging_models.items():\n",
    "    print(f\"\\nEvaluating {model_name}...\")\n",
    "    \n",
    "    # Initialize tracking\n",
    "    best_cv_scores[model_name] = float('inf')\n",
    "    all_results['bagged'][model_name] = []\n",
    "    \n",
    "    # Run through permutations\n",
    "    for perm_idx in range(n_permutations):\n",
    "        random_state = 1312 + perm_idx\n",
    "        indices = np.random.RandomState(random_state).permutation(len(X_dev))\n",
    "        X_permuted, y_permuted = X_dev[indices], y_dev[indices]\n",
    "        \n",
    "        kf = KFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "        fold_scores = []\n",
    "        \n",
    "        for fold_idx, (train_idx, val_idx) in enumerate(kf.split(X_permuted)):\n",
    "            # Get fold data\n",
    "            X_fold_train, X_fold_val = X_permuted[train_idx], X_permuted[val_idx]\n",
    "            y_fold_train, y_fold_val = y_permuted[train_idx], y_permuted[val_idx]\n",
    "            \n",
    "            # Preprocess\n",
    "            X_fold_train_df = pd.DataFrame(X_fold_train)\n",
    "            X_fold_val_df = pd.DataFrame(X_fold_val)\n",
    "            \n",
    "            for col in X_fold_train_df.columns:\n",
    "                fill_value = X_fold_train_df[col].mean()\n",
    "                X_fold_train_df[col] = X_fold_train_df[col].fillna(fill_value)\n",
    "                X_fold_val_df[col] = X_fold_val_df[col].fillna(fill_value)\n",
    "            \n",
    "            X_fold_train_scaled, mu, d = fit_transform_data(X_fold_train_df.values)\n",
    "            X_fold_val_scaled = transform_data(X_fold_val_df.values, mu, d)\n",
    "\n",
    "            # Ensure both train and val sets have the same columns after one-hot encoding\n",
    "            X_fold_train_scaled = pd.DataFrame(X_fold_train_scaled)\n",
    "            X_fold_val_scaled = pd.DataFrame(X_fold_val_scaled)\n",
    "            X_fold_val_scaled = X_fold_val_scaled.reindex(columns=X_fold_train_scaled.columns, fill_value=0)\n",
    "            columns = X_fold_train_scaled.columns.tolist()\n",
    "            \n",
    "            # Train and evaluate\n",
    "            model = copy.deepcopy(base_model)\n",
    "            model.fit(X_fold_train_scaled, y_fold_train)\n",
    "            y_pred = model.predict(X_fold_val_scaled)\n",
    "            mse = mean_squared_error(y_fold_val, y_pred)\n",
    "            rmse = np.sqrt(mse)\n",
    "            fold_scores.append(rmse)\n",
    "        \n",
    "        # Average the fold scores\n",
    "        avg_rmse = np.mean(fold_scores)\n",
    "        all_results['bagged'][model_name].append(avg_rmse)\n",
    "        \n",
    "        # Check if this is the best score\n",
    "        if avg_rmse < best_cv_scores[model_name]:\n",
    "            best_cv_scores[model_name] = avg_rmse\n",
    "            \n",
    "            # Train on all dev data\n",
    "            X_dev_df = pd.DataFrame(X_dev)\n",
    "            for col in X_dev_df.columns:\n",
    "                X_dev_df[col] = X_dev_df[col].fillna(X_dev_df[col].mean())\n",
    "            \n",
    "            X_dev_scaled, mu, d = fit_transform_data(X_dev_df.values)\n",
    "            scaler = [mu, d]\n",
    "            \n",
    "            best_model = copy.deepcopy(base_model)\n",
    "            best_model.fit(X_dev_scaled, y_dev)\n",
    "            best_estimators[model_name] = (best_model, scaler)\n",
    "    \n",
    "    print(f\"{model_name} - Best CV RMSE: {best_cv_scores[model_name]:.4f}\")\n",
    "\n",
    "# Final evaluation on the test set\n",
    "print(\"\\n=== FINAL MODEL EVALUATION ON TEST SET ===\")\n",
    "test_results = {}\n",
    "\n",
    "# Prepare test data\n",
    "X_final_test_df = pd.DataFrame(X_final_test)\n",
    "\n",
    "# Evaluate each model on the test set\n",
    "for model_name, (model, scaler) in best_estimators.items():\n",
    "    # Prepare test data using the same preprocessing as the model was trained with\n",
    "    X_test_processed = X_final_test_df.copy()\n",
    "    \n",
    "    # Fill NAs with training means (stored in scaler)\n",
    "    for col in X_test_processed.columns:\n",
    "        # If test data has NaN values, fill with the mean from training\n",
    "        if X_test_processed[col].isna().any():\n",
    "            # Assuming we can access feature means from the scaler\n",
    "            X_test_processed[col] = X_test_processed[col].fillna(X_test_processed[col].mean())\n",
    "    \n",
    "    # Apply the same scaling as during training\n",
    "    X_test_scaled = transform_data(X_test_processed.values, scaler[0], scaler[1])\n",
    "\n",
    "    # Make sure the test set has the same columns as the training set\n",
    "    X_test_scaled = pd.DataFrame(X_test_scaled)\n",
    "    X_test_scaled = X_test_scaled.reindex(columns=columns, fill_value=0)\n",
    "    \n",
    "    # Make predictions and calculate RMSE\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    test_rmse = np.sqrt(mean_squared_error(y_final_test, y_pred))\n",
    "    test_results[model_name] = test_rmse\n",
    "    \n",
    "    print(f\"{model_name} - Test RMSE: {test_rmse:.4f}\")\n",
    "\n",
    "# Find the best model based on test performance\n",
    "best_test_model = min(test_results, key=test_results.get)\n",
    "best_test_rmse = test_results[best_test_model]\n",
    "\n",
    "print(\"\\n=== BEST MODEL SELECTION ===\")\n",
    "print(f\"Best Model on Test Set: {best_test_model}\")\n",
    "print(f\"Best Test RMSE: {best_test_rmse:.4f}\")\n",
    "\n",
    "# If the best model has hyperparameters, show them\n",
    "if best_test_model in best_params and best_params[best_test_model]:\n",
    "    print(f\"Best Parameters: {best_params[best_test_model]}\")\n",
    "\n",
    "# Print summary of all models sorted by test RMSE performance\n",
    "print(\"\\n=== MODEL PERFORMANCE SUMMARY (sorted by Test RMSE) ===\")\n",
    "sorted_models = sorted(test_results.items(), key=lambda x: x[1])\n",
    "for model_name, rmse in sorted_models:\n",
    "    # Identify which category this model belongs to\n",
    "    category = None\n",
    "    if model_name in models:\n",
    "        category = \"vanilla\"\n",
    "    elif model_name in boosted_models:\n",
    "        category = \"boosted\"\n",
    "    elif model_name in bagging_models:\n",
    "        category = \"bagged\"\n",
    "    \n",
    "    print(f\"{model_name} ({category}) - Test RMSE: {rmse:.4f}\")\n",
    "\n",
    "# Visualize the results\n",
    "plt.figure(figsize=(12, 8))\n",
    "model_categories = {\n",
    "    'vanilla': [m for m in test_results if m in models],\n",
    "    'boosted': [m for m in test_results if m in boosted_models],\n",
    "    'bagged': [m for m in test_results if m in bagging_models]\n",
    "}\n",
    "\n",
    "colors = {'vanilla': 'blue', 'boosted': 'green', 'bagged': 'orange'}\n",
    "for cat, models_list in model_categories.items():\n",
    "    for model in models_list:\n",
    "        plt.bar(model, test_results[model], color=colors[cat], alpha=0.7)\n",
    "\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.ylabel('Test RMSE')\n",
    "plt.title('Model Performance Comparison')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with warnings.catch_warnings():\n",
    "#     warnings.simplefilter(\"ignore\")\n",
    "# # Perform grid search for each model\n",
    "#     best_estimators_pca = {}\n",
    "#     for name, (model, params) in models.items():\n",
    "#         grid_search = GridSearchCV(model, params, cv=5, scoring='neg_mean_squared_error')\n",
    "#         grid_search.fit(X_pca_train, y_pca_train)\n",
    "#         best_estimators_pca[name] = grid_search.best_estimator_\n",
    "#         print(f\"Best parameters for {name} with PCA: {grid_search.best_params_}\")\n",
    "\n",
    "#     # Use boosting to improve the results\n",
    "#     boosted_models_pca = {\n",
    "#         'AdaBoost': AdaBoostRegressor(estimator=best_estimators_pca['DecisionTree'], n_estimators=100, random_state=1312),\n",
    "#         'GradientBoosting': GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, random_state=1312),\n",
    "#         'ols': AdaBoostRegressor(estimator=best_estimators_pca['OLS'], n_estimators=100, random_state=1312),\n",
    "#         'Ridge': AdaBoostRegressor(estimator=best_estimators_pca['Ridge'], n_estimators=100, random_state=1312),\n",
    "#         'Lasso': AdaBoostRegressor(estimator=best_estimators_pca['Lasso'], n_estimators=100, random_state=1312)\n",
    "#     }\n",
    "\n",
    "#     # Evaluate the boosted models using cross-validation\n",
    "#     for name, model in boosted_models_pca.items():\n",
    "#         scores_pca = cross_val_score(model, X_pca_train, y_pca_train, cv=5, scoring='neg_mean_squared_error')\n",
    "#         rmse_scores_pca = np.sqrt(-scores_pca)\n",
    "#         print(f\"RMSE for {name} with boosting and PCA: {rmse_scores_pca.mean()}\")\n",
    "\n",
    "#     # Use bagging and cross-validation to estimate the RMSE generalization error\n",
    "#     bagging_models_pca = {\n",
    "#         'RandomForest': BaggingRegressor(estimator=best_estimators_pca['RandomForest'], n_estimators=10, random_state=1312),\n",
    "#         'DecisionTree': BaggingRegressor(estimator=best_estimators_pca['DecisionTree'], n_estimators=10, random_state=1312),\n",
    "#         'KNN': BaggingRegressor(estimator=best_estimators_pca['KNN'], n_estimators=10, random_state=1312),\n",
    "#         'OLS': BaggingRegressor(estimator=best_estimators_pca['OLS'], n_estimators=10, random_state=1312), # Not recommended\n",
    "#         'Ridge': BaggingRegressor(estimator=best_estimators_pca['Ridge'], n_estimators=10, random_state=1312),\n",
    "#         'Lasso': BaggingRegressor(estimator=best_estimators_pca['Lasso'], n_estimators=10, random_state=1312)\n",
    "#     }\n",
    "\n",
    "#     for name, model in bagging_models_pca.items():\n",
    "#         scores_pca = cross_val_score(model, X_pca_train, y_pca_train, cv=5, scoring='neg_mean_squared_error')\n",
    "#         rmse_scores_pca = np.sqrt(-scores_pca)\n",
    "#         print(f\"RMSE for {name} with bagging and PCA: {rmse_scores_pca.mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Evaluate the best models on the test set\n",
    "# for name, model in best_estimators.items():\n",
    "#     model.fit(X_train, y_train)\n",
    "#     y_pred = model.predict(X_test)\n",
    "#     rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "#     print(f\"RMSE for {name} on test set: {rmse}\")\n",
    "\n",
    "# print(\"\")\n",
    "\n",
    "# for name, model in best_estimators_pca.items():\n",
    "#     model.fit(X_pca_train, y_pca_train)\n",
    "#     y_pred_pca = model.predict(X_pca_test)\n",
    "#     rmse_pca = np.sqrt(mean_squared_error(y_pca_test, y_pred_pca))\n",
    "#     print(f\"RMSE for {name} on test set with PCA: {rmse_pca}\")\n",
    "\n",
    "# print(\"\")\n",
    "# print(f\"RMSE for {name} on test set: {np.min(rmse)}\")\n",
    "# print(f\"RMSE for {name} on test set with PCA: {np.min(rmse_pca)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.base import clone\n",
    "\n",
    "def compute_epe_with_small_labeled(model, X_labeled, y_labeled, X_unlabeled, n_bootstraps=100):\n",
    "    \"\"\"\n",
    "    Compute EPE decomposition ( + Bias + Variance) using a small labeled subset and unlabeled data.\n",
    "    \n",
    "    Args:\n",
    "        model: Pre-trained Lasso model (used for hyperparameters and ).\n",
    "        X_labeled: Labeled subset features (shape: [n_labeled_samples, n_features]).\n",
    "        y_labeled: Labeled subset targets (shape: [n_labeled_samples]).\n",
    "        X_unlabeled: Unlabeled data features (shape: [n_unlabeled_samples, n_features]).\n",
    "        n_bootstraps: Number of bootstrap iterations (default: 100).\n",
    "    \n",
    "    Returns:\n",
    "        epe: Total Expected Prediction Error.\n",
    "        sigma_e_sq: Irreducible error.\n",
    "        bias_sq: Squared bias.\n",
    "        variance: Prediction variance.\n",
    "    \"\"\"\n",
    "    # Step 1: Compute irreducible error () using the labeled subset\n",
    "    y_pred_labeled = model.predict(X_labeled)\n",
    "    sigma_e_sq = np.var(y_labeled - y_pred_labeled, ddof=1)  # Unbiased estimate\n",
    "\n",
    "    # Step 2: Bootstrap training on the labeled subset to estimate bias and variance\n",
    "    n_labeled = X_labeled.shape[0]\n",
    "    n_unlabeled = X_unlabeled.shape[0]\n",
    "    \n",
    "    # Arrays to store predictions for labeled and unlabeled data\n",
    "    preds_labeled = np.zeros((n_bootstraps, n_labeled))\n",
    "    preds_unlabeled = np.zeros((n_bootstraps, n_unlabeled))\n",
    "\n",
    "    for i in range(n_bootstraps):\n",
    "        # Create bootstrap sample\n",
    "        indices = np.random.choice(n_labeled, n_labeled, replace=True)\n",
    "        X_boot, y_boot = X_labeled[indices], y_labeled[indices]\n",
    "        \n",
    "        # Clone model to retain hyperparameters and train on bootstrap sample\n",
    "        m = clone(model)\n",
    "        m.fit(X_boot, y_boot)\n",
    "        \n",
    "        # Predict on labeled and unlabeled data\n",
    "        preds_labeled[i] = m.predict(X_labeled)\n",
    "        preds_unlabeled[i] = m.predict(X_unlabeled)\n",
    "\n",
    "    # Step 3: Compute bias (using labeled subset)\n",
    "    mean_preds_labeled = np.mean(preds_labeled, axis=0)\n",
    "    bias_sq = np.mean((mean_preds_labeled - y_labeled) ** 2)\n",
    "\n",
    "    # Step 4: Compute variance (using unlabeled data)\n",
    "    variance = np.mean(np.var(preds_unlabeled, axis=0, ddof=1))\n",
    "\n",
    "    # Step 5: Total EPE\n",
    "    epe = sigma_e_sq + bias_sq + variance\n",
    "\n",
    "    return epe, sigma_e_sq, bias_sq, variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal alpha: 0.1624\n",
      "CV alpha with 1-std-rule: 0.3360\n",
      "Final RMSE on test set: 38.1111\n",
      "Expected Prediction Error (EPE): 1267.6513\n",
      "Irreducible Error (): 365.1533\n",
      "Bias: 578.4914\n",
      "Variance: 324.0066\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Define the range of alphas for Lasso\n",
    "alphas = np.logspace(-3, 3, 20)  # Example range of alpha values\n",
    "K = 5  # Number of cross-validation folds\n",
    "\n",
    "# Store RMSE for each alpha\n",
    "RMSE = []\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    # Perform cross-validation for each alpha\n",
    "    for alpha in alphas:\n",
    "        model = Lasso(alpha=alpha, max_iter=10000)\n",
    "        scores = cross_val_score(model, X_train, y_train, cv=K, scoring='neg_mean_squared_error')\n",
    "        rmse_scores = np.sqrt(-scores)  # Convert negative MSE to RMSE\n",
    "        RMSE.append(rmse_scores)\n",
    "\n",
    "    RMSE = np.array(RMSE)\n",
    "    meanRMSE = np.mean(RMSE, axis=1)  # Mean RMSE for each alpha\n",
    "    jOpt = np.argmin(meanRMSE)  # Index of the optimal alpha (smallest RMSE)\n",
    "\n",
    "# Calculate the standard error for the best alpha\n",
    "seRMSE = np.std(RMSE, axis=1) / np.sqrt(K)\n",
    "\n",
    "# Find the largest alpha within one standard error of the optimal alpha\n",
    "J = np.where(meanRMSE[jOpt] + seRMSE[jOpt] > meanRMSE)[0]\n",
    "Alpha_CV_1StdRule = alphas[J[-1]]\n",
    "\n",
    "print(f\"Optimal alpha: {alphas[jOpt]:.4f}\")\n",
    "print(f\"CV alpha with 1-std-rule: {Alpha_CV_1StdRule:.4f}\")\n",
    "\n",
    "# Train the final model with the selected alpha\n",
    "final_model = Lasso(alpha=Alpha_CV_1StdRule, max_iter=10000)\n",
    "final_model.fit(X_dev, y_dev)\n",
    "# Evaluate the final model on the test set\n",
    "final_rmse = np.sqrt(mean_squared_error(y_final_test, final_model.predict(X_final_test)))\n",
    "print(f\"Final RMSE on test set: {final_rmse:.4f}\")\n",
    "\n",
    "epe, std, bias, var = compute_epe_with_small_labeled(final_model, X_dev, y_dev, X_new)\n",
    "\n",
    "\n",
    "print(f\"Expected Prediction Error (EPE): {epe:.4f}\")\n",
    "print(f\"Irreducible Error (): {std:.4f}\")\n",
    "print(f\"Bias: {bias:.4f}\")\n",
    "print(f\"Variance: {var:.4f}\")\n",
    "\n",
    "\n",
    "# Predict on X_new using the final model\n",
    "y_new_pred = final_model.predict(X_new)\n",
    "\n",
    "# Save the predicted values to a CSV file\n",
    "#np.savetxt('sample_estimate_prediction_s215160.csv', y_new_pred, delimiter=',',fmt='%f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected RMSE: 35.6041\n"
     ]
    }
   ],
   "source": [
    "# Expected RMSE\n",
    "\n",
    "rmse_hat = np.sqrt(epe)\n",
    "\n",
    "print(f\"Expected RMSE: {rmse_hat:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
